{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "amber-excitement",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "featured-anime",
   "metadata": {},
   "source": [
    "# Reference: \n",
    "https://d2l.ai/chapter_linear-networks/linear-regression-scratch.html <br>\n",
    "https://tangshusen.me/Dive-into-DL-PyTorch/#/chapter03_DL-basics/3.3_linear-regression-pytorch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "exterior-handling",
   "metadata": {},
   "source": [
    "#  Basic elements:\n",
    "1. training data\n",
    "2. model\n",
    "3. loss function\n",
    "4. optimization function"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "detailed-sender",
   "metadata": {},
   "source": [
    "# Implement the Linear Regression from Scratch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "broad-december",
   "metadata": {},
   "source": [
    "## Prepare data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "breathing-shipping",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_inputs = 2                                                       # number of input feature\n",
    "num_examples = 1000                                                  # number of input\n",
    "true_w = [2, -3.4]                                                   # true w\n",
    "true_b = 4.2                                                         # true bias \n",
    "X = torch.randn(num_examples, num_inputs,dtype=torch.float32)        # X\n",
    "y = true_w[0] * X[:, 0] + true_w[1] * X[:, 1] + true_b               # y\n",
    "y += torch.tensor(np.random.normal(0, 0.01, size=y.size()),dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "tested-acrylic",
   "metadata": {},
   "source": [
    "## Read  Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "sustained-slide",
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_iter(batch_size, X, y):\n",
    "    num_examples = len(X)\n",
    "    indices = list(range(num_examples)) \n",
    "    random.shuffle(indices)   # shuffle data by shuffling each sample's index \n",
    "    for i in range(0, num_examples, batch_size):\n",
    "        j = torch.LongTensor(indices[i: min(i + batch_size, num_examples)]) # at last time, may not eough bacth_size\n",
    "        yield  X.index_select(0, j), y.index_select(0, j)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "exotic-cable",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.3273, -2.2829],\n",
      "        [ 1.0348,  1.1587],\n",
      "        [ 0.2759, -0.8850],\n",
      "        [-0.6894, -0.3430],\n",
      "        [-0.5639,  0.1136],\n",
      "        [-0.6001, -0.2558],\n",
      "        [-1.3017,  1.2472],\n",
      "        [-0.6990,  1.3417],\n",
      "        [-0.4300,  1.4635],\n",
      "        [ 0.4237, -0.8379]]) tensor([11.3000,  2.3287,  7.7660,  3.9756,  2.7125,  3.8669, -2.6294, -1.7832,\n",
      "        -1.6199,  7.8921])\n"
     ]
    }
   ],
   "source": [
    "batch_size = 10\n",
    "\n",
    "for X_batch, y_batch in data_iter(batch_size, X, y):\n",
    "    print(X_batch, y_batch)\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "early-hardware",
   "metadata": {},
   "source": [
    "## Initialize parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "statistical-cooling",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([2, 1]), torch.Size([1]))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w = torch.tensor(np.random.normal(0, 0.01, (num_inputs, 1)), dtype=torch.float32)\n",
    "b = torch.zeros(1, dtype=torch.float32)\n",
    "\n",
    "w.requires_grad_(requires_grad=True)\n",
    "b.requires_grad_(requires_grad=True) \n",
    "\n",
    "w.shape,b.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "indirect-ecuador",
   "metadata": {},
   "source": [
    "## Define Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "immune-magnet",
   "metadata": {},
   "outputs": [],
   "source": [
    "def linreg(X, w, b): \n",
    "    return torch.mm(X, w) + b"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "different-cassette",
   "metadata": {},
   "source": [
    "## Define loss function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "descending-scanner",
   "metadata": {},
   "outputs": [],
   "source": [
    "def squared_loss(y_hat, y):  \n",
    "    # return a vector, besides,MSELoss in pyTorch doesn't divided by 2\n",
    "    return (y_hat - y.view(y_hat.size())) ** 2 / 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "popular-magnet",
   "metadata": {},
   "source": [
    "## Define optimization function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "saving-sweet",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sgd(params, lr, batch_size):  \n",
    "    for param in params:\n",
    "        param.data -= lr * param.grad / batch_size  # use param.data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eight-bosnia",
   "metadata": {},
   "source": [
    "## Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "minor-tunisia",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1, loss 0.051443\n",
      "epoch 2, loss 0.000237\n",
      "epoch 3, loss 0.000051\n",
      "epoch 4, loss 0.000050\n",
      "epoch 5, loss 0.000050\n"
     ]
    }
   ],
   "source": [
    "lr = 0.03\n",
    "num_epochs = 5\n",
    "net = linreg\n",
    "loss = squared_loss\n",
    "\n",
    "for epoch in range(num_epochs): \n",
    "\n",
    "    for X_batch, y_batch in data_iter(batch_size, X, y):\n",
    "        l = loss(net(X_batch, w, b), y_batch).sum()  \n",
    "        l.backward()   # Compute gradient on l with respect to [w,b]\n",
    "        sgd([w, b], lr, batch_size) \n",
    "\n",
    "        # zero gradient\n",
    "        w.grad.data.zero_()\n",
    "        b.grad.data.zero_()\n",
    "        \n",
    "    train_l = loss(net(X, w, b), y)\n",
    "    print('epoch %d, loss %f' % (epoch + 1, train_l.mean().item()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "atmospheric-single",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2, -3.4] \t\t tensor([[ 1.9998],\n",
      "        [-3.3994]], requires_grad=True)\n",
      "4.2 \t\t tensor([4.2000], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "print(true_w, '\\t\\t', w)\n",
    "print(true_b, '\\t\\t', b)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "accurate-framework",
   "metadata": {},
   "source": [
    "# Implement the Linear Regression by using Pytorch module\n",
    "\n",
    "* torch.utils.data\n",
    "* torch.nn\n",
    "* torch.nn.init\n",
    "* torch.optim"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "enclosed-debut",
   "metadata": {},
   "source": [
    "## Read Data (Using DataSet, DataLoader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "pleased-teach",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.utils.data as Data\n",
    "\n",
    "batch_size = 10\n",
    "# combine X and y\n",
    "dataset = Data.TensorDataset(X, y)\n",
    "# load batch \n",
    "data_iter = Data.DataLoader(dataset, batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "excess-chassis",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-1.0294,  0.7481],\n",
      "        [-1.1275,  0.2111],\n",
      "        [ 0.1487, -0.7129],\n",
      "        [-0.3390, -0.5591],\n",
      "        [ 0.6595, -0.3149],\n",
      "        [-1.5672, -1.6979],\n",
      "        [ 0.1037,  0.8913],\n",
      "        [ 1.2237, -0.2482],\n",
      "        [ 2.2195,  0.9758],\n",
      "        [-0.6770,  0.1716]]) tensor([-0.4062,  1.2368,  6.9290,  5.4332,  6.6043,  6.8430,  1.3789,  7.4874,\n",
      "         5.3312,  2.2704])\n"
     ]
    }
   ],
   "source": [
    "for X, y in data_iter:\n",
    "    print(X, y)\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "communist-section",
   "metadata": {},
   "source": [
    "`torch.nn` only supports the input of one batch of samples and does not support single sample input. \n",
    "If there is only a single sample `x`, use `x.unsqueeze(0)` to add one dimension.\n",
    "in this way x.shape from `(torch.Size([d])` to `torch.Size([1, d])`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "specific-marking",
   "metadata": {},
   "source": [
    "## Define model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "adopted-automation",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "net = nn.Sequential(nn.Linear(2, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "unable-cattle",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter containing:\n",
      "tensor([[-0.3538, -0.0508]], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([0.2526], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "# net.parameters() return a generator\n",
    "for param in net.parameters():\n",
    "    print(param)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "activated-buffer",
   "metadata": {},
   "source": [
    "## Initialize parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "steady-induction",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([0.], requires_grad=True)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torch.nn import init\n",
    "\n",
    "init.normal_(net[0].weight, mean=0, std=0.01)\n",
    "init.constant_(net[0].bias, val=0)  # another way: net[0].bias.data.fill_(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "dense-ranking",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter containing:\n",
      "tensor([[0.0053, 0.0011]], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([0.], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "for param in net.parameters():\n",
    "    print(param)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "artificial-norway",
   "metadata": {},
   "source": [
    "## Define loss function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "material-greeting",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = nn.MSELoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fabulous-orange",
   "metadata": {},
   "source": [
    "## Define optimization function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "wired-abortion",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SGD (\n",
      "Parameter Group 0\n",
      "    dampening: 0\n",
      "    lr: 0.03\n",
      "    momentum: 0\n",
      "    nesterov: False\n",
      "    weight_decay: 0\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "optimizer = optim.SGD(net.parameters(), lr=0.03)\n",
    "print(optimizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "higher-friday",
   "metadata": {},
   "source": [
    "we can set different learning rate for different subnets(useful for finetune) , like \n",
    "```\n",
    "optimizer =optim.SGD([\n",
    "                {'params': net.subnet1.parameters()}, # lr=0.03\n",
    "                {'params': net.subnet2.parameters(), 'lr': 0.01}\n",
    "            ], lr=0.03)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "looking-valentine",
   "metadata": {},
   "source": [
    "## Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "desperate-aging",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1, loss: 0.000372\n",
      "epoch 2, loss: 0.000116\n",
      "epoch 3, loss: 0.000090\n",
      "epoch 4, loss: 0.000053\n",
      "epoch 5, loss: 0.000120\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 5\n",
    "for epoch in range(1, num_epochs + 1):\n",
    "    for X_batch, y_batch in data_iter:\n",
    "        output = net(X_batch)\n",
    "        l = loss(output, y_batch.view(-1, 1))\n",
    "        optimizer.zero_grad() # equivalent to net.zero_grad()\n",
    "        l.backward()\n",
    "        optimizer.step()\n",
    "    print('epoch %d, loss: %f' % (epoch, l.item()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "dedicated-conservation",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2, -3.4] Parameter containing:\n",
      "tensor([[ 1.9994, -3.4011]], requires_grad=True)\n",
      "4.2 Parameter containing:\n",
      "tensor([4.2005], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "dense = net[0]\n",
    "print(true_w, dense.weight)\n",
    "print(true_b, dense.bias)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "canadian-coral",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
