{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "olive-maximum",
   "metadata": {},
   "source": [
    "# References\n",
    "https://tangshusen.me/Dive-into-DL-PyTorch/#/chapter03_DL-basics/3.6_softmax-regression-scratch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "faced-baseball",
   "metadata": {},
   "source": [
    "#  Basic elements:\n",
    "\n",
    "1. training data\n",
    "2. model\n",
    "3. loss function\n",
    "4. optimization function\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "distributed-latitude",
   "metadata": {},
   "source": [
    "# Implement the Softmax Regression from Scratch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "noted-motorcycle",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import numpy as np\n",
    "import torchvision.transforms as transforms"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "wireless-honey",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "homeless-black",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 256\n",
    "mnist_train = torchvision.datasets.FashionMNIST(root='../data', \n",
    "                                                train=True, download=False, transform=transforms.ToTensor())\n",
    "mnist_test = torchvision.datasets.FashionMNIST(root='../data', \n",
    "                                               train=False, download=False, transform=transforms.ToTensor())\n",
    "\n",
    "train_iter = torch.utils.data.DataLoader(mnist_train, batch_size=batch_size, shuffle=True, num_workers=4)\n",
    "test_iter = torch.utils.data.DataLoader(mnist_test, batch_size=batch_size, shuffle=False, num_workers=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "smaller-proof",
   "metadata": {},
   "source": [
    "## Initialize Parameters\n",
    "\n",
    "* For the sample problem, the number of class is 10, size of input vector for each sample is 28x28=784\n",
    "* Thus the W.shape is (784,10) b.shape is (1,10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "earlier-eating",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([784, 10]), torch.Size([10]))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_inputs = 28*28  \n",
    "num_outputs = 10\n",
    "\n",
    "W = torch.tensor(np.random.normal(0, 0.01, size=(num_inputs, num_outputs)), dtype=torch.float)\n",
    "b = torch.zeros(num_outputs, dtype=torch.float)\n",
    "\n",
    "W.requires_grad_(requires_grad=True)\n",
    "b.requires_grad_(requires_grad=True) \n",
    "\n",
    "W.shape, b.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "material-hunger",
   "metadata": {},
   "source": [
    "## Define model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "toxic-garbage",
   "metadata": {},
   "outputs": [],
   "source": [
    "def softmax(O):\n",
    "    O_exp = O.exp()\n",
    "    partition = O_exp.sum(dim=1, keepdim=True)\n",
    "    return O_exp / partition   # broadcast\n",
    "\n",
    "def net(X):\n",
    "    return softmax(torch.mm(X.view((-1, num_inputs)), W) + b)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "intelligent-allah",
   "metadata": {},
   "source": [
    "## Define loss function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "photographic-night",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cross_entropy(y_hat, y):\n",
    "    return - torch.log(y_hat.gather(1, y.view(-1, 1)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "technical-duration",
   "metadata": {},
   "source": [
    "## Define optimization function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "identical-monte",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sgd(params, lr, batch_size):  \n",
    "    for param in params:\n",
    "        param.data -= lr * param.grad / batch_size  # use param.data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "monetary-insulation",
   "metadata": {},
   "source": [
    "## Evaluation (accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "given-civilization",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([2, 2]) 0.5\n"
     ]
    }
   ],
   "source": [
    "def accuracy(y_hat, y):\n",
    "    return (y_hat.argmax(dim=1) == y).float().mean().item()\n",
    "\n",
    "# explanation:\n",
    "y = torch.tensor([1,2])\n",
    "y_hat = torch.tensor([[0.1, 0.3, 0.6],\n",
    "                      [0.3, 0.2, 0.5]])\n",
    "print(y_hat.argmax(dim=1),(y_hat.argmax(dim=1) == y).float().mean().item())\n",
    "\n",
    "\n",
    "def evaluate_accuracy(data_iter, net):\n",
    "    acc_sum, n = 0.0, 0\n",
    "    for X, y in data_iter:\n",
    "        acc_sum += (net(X).argmax(dim=1) == y).float().sum().item()\n",
    "        n += y.shape[0]\n",
    "    return acc_sum / n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "uniform-torture",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.17428333333333335"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate_accuracy(train_iter,net)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cloudy-hughes",
   "metadata": {},
   "source": [
    "## Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "social-worst",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1, loss 0.7867, train acc 0.752, test acc 0.794\n",
      "epoch 2, loss 0.5703, train acc 0.813, test acc 0.810\n",
      "epoch 3, loss 0.5245, train acc 0.826, test acc 0.822\n",
      "epoch 4, loss 0.5000, train acc 0.833, test acc 0.826\n",
      "epoch 5, loss 0.4861, train acc 0.837, test acc 0.827\n"
     ]
    }
   ],
   "source": [
    "num_epochs, lr = 5, 0.1\n",
    "\n",
    "def train_softmax(net, train_iter, test_iter, loss, num_epochs, batch_size,\n",
    "              params=None, lr=None):\n",
    "    for epoch in range(num_epochs):\n",
    "        train_l_sum, train_acc_sum, n = 0.0, 0.0, 0\n",
    "        for X, y in train_iter:\n",
    "            y_hat = net(X)\n",
    "            l = loss(y_hat, y).sum()\n",
    "            \n",
    "            if params is not None and params[0].grad is not None:\n",
    "                for param in params:\n",
    "                    param.grad.data.zero_()\n",
    "                    \n",
    "            l.backward()\n",
    "\n",
    "            # optimize parameters\n",
    "            sgd(params, lr, batch_size)\n",
    "\n",
    "            train_l_sum += l.item()\n",
    "            train_acc_sum += (y_hat.argmax(dim=1) == y).sum().item()\n",
    "            n += y.shape[0]\n",
    "            \n",
    "        test_acc = evaluate_accuracy(test_iter, net)\n",
    "        print('epoch %d, loss %.4f, train acc %.3f, test acc %.3f'\n",
    "              % (epoch + 1, train_l_sum / n, train_acc_sum / n, test_acc))\n",
    "\n",
    "train_softmax(net, train_iter, test_iter, cross_entropy, num_epochs, batch_size, [W, b], lr)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "indonesian-cinema",
   "metadata": {},
   "source": [
    "## Make Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "bright-thickness",
   "metadata": {},
   "outputs": [],
   "source": [
    "## ...."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "expired-opportunity",
   "metadata": {},
   "source": [
    "# Implement the Softmax Regression by using Pytorch Module"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "interim-england",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "heated-screening",
   "metadata": {},
   "outputs": [],
   "source": [
    "# same as above"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "three-buying",
   "metadata": {},
   "source": [
    "## Define model & initialize parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "double-rally",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "num_inputs = 784\n",
    "num_outputs = 10\n",
    "\n",
    "class FlattenLayer(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(FlattenLayer, self).__init__()\n",
    "    def forward(self, x): # x shape: (batch, *, *, ...)\n",
    "        return x.view(x.shape[0], -1)\n",
    "    \n",
    "class LinearNet(nn.Module):\n",
    "    def __init__(self, num_inputs, num_outputs):\n",
    "        super(LinearNet, self).__init__()\n",
    "        self.linear = nn.Linear(num_inputs, num_outputs)\n",
    "    def forward(self, x): # x shape: (batch, 1, 28, 28)\n",
    "        y = self.linear(x.view(x.shape[0], -1))\n",
    "        return y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "blank-vegetarian",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sequential(\n",
      "  (flatten): FlattenLayer()\n",
      "  (linear): Linear(in_features=784, out_features=10, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "net = nn.Sequential()\n",
    "net.add_module('flatten', FlattenLayer())\n",
    "net.add_module('linear',  nn.Linear(num_inputs, num_outputs))\n",
    "\n",
    "print(net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "radio-bronze",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], requires_grad=True)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch.nn.init as init\n",
    "init.normal_(net.linear.weight, mean=0, std=0.01)\n",
    "init.constant_(net.linear.bias, val=0) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aggressive-penetration",
   "metadata": {},
   "source": [
    "## Define loss function & optimization algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "higher-relay",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(net.parameters(), lr=0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bound-maldives",
   "metadata": {},
   "source": [
    "`CrossEntropyLoss in PyTorch  = softmax + CrossEntropyLoss` which means the output of the network is the value of linear regression instead of probability"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "grave-powell",
   "metadata": {},
   "source": [
    "## Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "constitutional-croatia",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 5\n",
    "\n",
    "def train_softmax_torch(net, train_iter, test_iter, loss, num_epochs, batch_size,\n",
    "              params=None, lr=None, optimizer=None):\n",
    "    for epoch in range(num_epochs):\n",
    "        train_l_sum, train_acc_sum, n = 0.0, 0.0, 0\n",
    "        for X, y in train_iter:\n",
    "            y_hat = net(X)\n",
    "            l = loss(y_hat, y).sum()\n",
    "\n",
    "            # zero gradient\n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            l.backward()\n",
    "        \n",
    "            optimizer.step() \n",
    "\n",
    "\n",
    "            train_l_sum += l.item()\n",
    "            train_acc_sum += (y_hat.argmax(dim=1) == y).sum().item()\n",
    "            n += y.shape[0]\n",
    "        test_acc = evaluate_accuracy(test_iter, net)\n",
    "        print('epoch %d, loss %.4f, train acc %.3f, test acc %.3f'\n",
    "              % (epoch + 1, train_l_sum / n, train_acc_sum / n, test_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "overall-rochester",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1, loss 0.0031, train acc 0.746, test acc 0.793\n",
      "epoch 2, loss 0.0022, train acc 0.814, test acc 0.808\n",
      "epoch 3, loss 0.0021, train acc 0.825, test acc 0.813\n",
      "epoch 4, loss 0.0020, train acc 0.831, test acc 0.821\n",
      "epoch 5, loss 0.0019, train acc 0.838, test acc 0.823\n"
     ]
    }
   ],
   "source": [
    "train_softmax_torch(net, train_iter, test_iter, loss, num_epochs, batch_size, None, None, optimizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "outer-level",
   "metadata": {},
   "source": [
    "## Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "accessory-engagement",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "relative-russia",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
